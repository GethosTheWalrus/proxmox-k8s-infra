variables:
  REGISTRY_PATH: "git.home:5050/mike/proxmox-k8s-infra"

stages:
  - build
  - configure
  - deploy
  - test
  - destroy

deploy-infra:
  stage: build
  image: 
    name: hashicorp/terraform:latest
    entrypoint: [""]
  before_script:
    - export TF_VAR_username=$(echo "$PVEUSER" | base64 -d)
    - export TF_VAR_password=$(echo "$PVEPASSWORD" | base64 -d)
    - export PROJECT_ID=5
    - export TF_USERNAME=$(echo "$GITLABUSERNAME" | base64 -d)
    - export TF_PASSWORD=$(echo "$GITLABACCESSTOKEN" | base64 -d)
    - export TF_ADDRESS="http://git.home/api/v4/projects/$PROJECT_ID/terraform/state/proxmox-k8s-infra"
    - terraform init -backend-config=address=${TF_ADDRESS} -backend-config=lock_address=${TF_ADDRESS}/lock -backend-config=unlock_address=${TF_ADDRESS}/lock -backend-config=username=${TF_USERNAME} -backend-config=password=${TF_PASSWORD} -backend-config=lock_method=POST -backend-config=unlock_method=DELETE -backend-config=retry_wait_min=5
  script:
    - terraform apply -parallelism=2 --auto-approve=true
    - terraform output vm_private_key > key
    - terraform output vm_public_key > key.pub
    - sed -i '1d;$d' key
    - chmod 600 key
    - cat key
  rules:
  - if: '$CI_COMMIT_BRANCH == "main"'
  artifacts:
    paths:
      - scripts
      - key
      - storage-class.yaml

# build-python-worker:
#   stage: build
#   image: docker:20.10.16
#   services:
#     - name: docker:20.10.16-dind
#       command: ["--insecure-registry=git.home:5050"]
#   before_script:
#     - mkdir -p /etc/docker
#     - |
#       cat > /etc/docker/daemon.json << EOF
#       {
#         "insecure-registries": ["git.home:5050"]
#       }
#       EOF
#     - apk add --no-cache curl
#     - docker login -u mike -p $GITLABACCESSTOKEN http://git.home:5050
#   script:
#     - docker build -t $REGISTRY_PATH/python-worker:latest workers/python
#     - docker push $REGISTRY_PATH/python-worker:latest

# build-typescript-worker:
#   stage: build
#   image: docker:20.10.16
#   services:
#     - name: docker:20.10.16-dind
#       command: ["--insecure-registry=git.home:5050"]
#   before_script:
#     - mkdir -p /etc/docker
#     - |
#       cat > /etc/docker/daemon.json << EOF
#       {
#         "insecure-registries": ["git.home:5050"]
#       }
#       EOF
#     - apk add --no-cache curl
#     - docker login -u mike -p $GITLABACCESSTOKEN http://git.home:5050
#   script:
#     - docker build -t $REGISTRY_PATH/typescript-worker:latest workers/typescript
#     - docker push $REGISTRY_PATH/typescript-worker:latest

# build-csharp-worker:
#   stage: build
#   image: docker:20.10.16
#   services:
#     - name: docker:20.10.16-dind
#       command: ["--insecure-registry=git.home:5050"]
#   before_script:
#     - mkdir -p /etc/docker
#     - |
#       cat > /etc/docker/daemon.json << EOF
#       {
#         "insecure-registries": ["git.home:5050"]
#       }
#       EOF
#     - apk add --no-cache curl
#     - docker login -u mike -p $GITLABACCESSTOKEN http://git.home:5050
#   script:
#     - docker build -t $REGISTRY_PATH/csharp-worker:latest workers/csharp
#     - docker push $REGISTRY_PATH/csharp-worker:latest

# build-go-worker:
#   stage: build
#   image: docker:20.10.16
#   services:
#     - name: docker:20.10.16-dind
#       command: ["--insecure-registry=git.home:5050"]
#   before_script:
#     - mkdir -p /etc/docker
#     - |
#       cat > /etc/docker/daemon.json << EOF
#       {
#         "insecure-registries": ["git.home:5050"]
#       }
#       EOF
#     - apk add --no-cache curl
#     - docker login -u mike -p $GITLABACCESSTOKEN http://git.home:5050
#   script:
#     - docker build -t $REGISTRY_PATH/go-worker:latest workers/go
#     - docker push $REGISTRY_PATH/go-worker:latest


init-master:
  stage: configure
  image:
    name: ubuntu:latest
  variables:
    K8S1: 192.168.69.80
    ROLE: master
    TOKEN: abcdef.0123456789abcdef
  before_script:
    - apt update && apt install -y openssh-client
  script:
  - ssh -i key -o StrictHostKeyChecking=no k8s@"$K8S1" "sudo ROLE=$ROLE TOKEN=$TOKEN bash -s" < scripts/install-k8s.sh
  - scp -i key -o StrictHostKeyChecking=no k8s@"$K8S1":~/hash $CI_PROJECT_DIR/hash
  rules:
  - if: $CI_COMMIT_TITLE =~ /-init$/
    when: always
  allow_failure: false
  needs:
    - deploy-infra
  artifacts:
    paths:
      - hash
      - key
      - scripts

init-workers:
  stage: configure
  image:
    name: ubuntu:latest
  variables:
    K8S1: 192.168.69.80
    K8S2: 192.168.69.81
    K8S3: 192.168.69.82
    K8S4: 192.168.69.83
    JOINTOKEN: abcdef.0123456789abcdef
    ROLE: worker
  before_script:
    - apt update && apt install -y openssh-client
  script:
    - scp -i key -o StrictHostKeyChecking=no k8s@"$K8S1":~/hash $CI_PROJECT_DIR/hash
    - ssh -i key -o StrictHostKeyChecking=no k8s@"$K8S2" "sudo ROLE=$ROLE bash -s" < $CI_PROJECT_DIR/scripts/install-k8s.sh $K8S1 $JOINTOKEN $(cat $CI_PROJECT_DIR/hash)
    - ssh -i key -o StrictHostKeyChecking=no k8s@"$K8S3" "sudo ROLE=$ROLE bash -s" < $CI_PROJECT_DIR/scripts/install-k8s.sh $K8S1 $JOINTOKEN $(cat $CI_PROJECT_DIR/hash)
    - ssh -i key -o StrictHostKeyChecking=no k8s@"$K8S4" "sudo ROLE=$ROLE bash -s" < $CI_PROJECT_DIR/scripts/install-k8s.sh $K8S1 $JOINTOKEN $(cat $CI_PROJECT_DIR/hash)
  rules:
  - if: $CI_COMMIT_TITLE =~ /-init$/
    when: always
    allow_failure: false
  needs:
    - deploy-infra
    - init-master


deploy-metallb:
  stage: deploy
  image:
    name: alpine/k8s:1.29.13
  variables:
    K8S1: 192.168.69.80
    METALLB_NAMESPACE: metallb-system
    IP_ADDRESS_RANGE: 192.168.69.95-192.168.69.100
  before_script:
    - apk --no-cache add openssh-client kubectl helm
  script:
    - mkdir ~/.kube
    - scp -i key -o StrictHostKeyChecking=no k8s@"$K8S1":~/.kube/config ~/.kube/config
    - export KUBECONFIG=~/.kube/config
    - chmod +x scripts/install-metallb.sh
    - scripts/install-metallb.sh
  rules:
    - if: '$CI_COMMIT_BRANCH == "main" && $CI_COMMIT_TITLE =~ /-init$/'
      when: always
    - when: manual
  dependencies:
    - init-master
    - init-workers

deploy-nginx:
  stage: deploy
  image:
    name: alpine/k8s:1.29.13
  variables:
    K8S1: 192.168.69.80
  before_script:
    - apk --no-cache add openssh-client
  script:
    - mkdir ~/.kube
    - scp -i key -o StrictHostKeyChecking=no k8s@"$K8S1":~/.kube/config ~/.kube/config
    - export KUBECONFIG=~/.kube/config
    - kubectl create deploy nginx --image nginx
    - kubectl expose deploy nginx --port 80 --type LoadBalancer
  rules:
  - when: always
  allow_failure: false
  needs:
    - init-master
    - init-workers
    - deploy-metallb

deploy-openebs:
  stage: deploy
  image:
    name: alpine/k8s:1.29.13
  variables:
    K8S1: 192.168.69.80
  before_script:
    - apk --no-cache add openssh-client kubectl helm
  script:
    - mkdir ~/.kube
    - scp -i key -o StrictHostKeyChecking=no k8s@"$K8S1":~/.kube/config ~/.kube/config
    - export KUBECONFIG=~/.kube/config
    - chmod +x scripts/install-openebs.sh
    - scripts/install-openebs.sh
    - echo "Applying storage class..."
    - kubectl apply -f storage-class.yaml
    - echo "Verifying storage class..."
    - kubectl get sc
    - echo "Verifying OpenEBS pods are running..."
    - kubectl get pods -n openebs
  rules:
    - if: '$CI_COMMIT_BRANCH == "main" && $CI_COMMIT_TITLE =~ /-init$/'
      when: always
    - if: '$CI_COMMIT_BRANCH == "main"'
      when: manual
  needs:
    - init-master
    - init-workers
    - deploy-metallb

deploy-temporal:
    stage: deploy
    image:
      name: alpine/k8s:1.29.13
    variables:
      K8S1: 192.168.69.80
      LOAD_BALANCER_IP: 192.168.69.98
    before_script:
      - apk --no-cache add openssh-client kubectl helm docker-cli
      # Configure Docker to use insecure registry
      - mkdir -p /etc/docker
      - |
        cat > /etc/docker/daemon.json << EOF
        {
          "insecure-registries": ["git.home:5050"]
        }
        EOF
      # Login to Docker Hub if credentials are provided
      - |
        if [ -n "$DOCKER_USERNAME" ] && [ -n "$DOCKER_PASSWORD" ]; then
          echo "Attempting to login to Docker Hub..."
          echo "Username: $DOCKER_USERNAME"
          echo "Password length: ${#DOCKER_PASSWORD}"
          # Try login with explicit registry
          docker login docker.io -u $DOCKER_USERNAME -p $DOCKER_PASSWORD
          # If that fails, try without specifying registry
          if [ $? -ne 0 ]; then
            echo "First login attempt failed, trying alternative method..."
            docker login -u $DOCKER_USERNAME -p $DOCKER_PASSWORD
          fi
        else
          echo "Docker credentials not provided"
          echo "DOCKER_USERNAME is set: $([ -n "$DOCKER_USERNAME" ] && echo 'yes' || echo 'no')"
          echo "DOCKER_PASSWORD is set: $([ -n "$DOCKER_PASSWORD" ] && echo 'yes' || echo 'no')"
        fi 
      # Create Kubernetes secret for Docker Hub credentials
      - |
        if [ -n "$DOCKER_USERNAME" ] && [ -n "$DOCKER_PASSWORD" ]; then
          echo "Creating Kubernetes secret for Docker Hub..."
          kubectl create secret docker-registry dockerhub-secret \
            --docker-server=docker.io \
            --docker-username=$DOCKER_USERNAME \
            --docker-password=$DOCKER_PASSWORD \
            --docker-email=$DOCKER_EMAIL \
            --namespace=temporal || true
        fi
    script:
      - mkdir ~/.kube
      - scp -i key -o StrictHostKeyChecking=no k8s@"$K8S1":~/.kube/config ~/.kube/config
      - export KUBECONFIG=~/.kube/config
      - chmod +x scripts/install-temporal.sh
      - scripts/install-temporal.sh
    rules:
      - if: '$CI_COMMIT_BRANCH == "main" && $CI_COMMIT_TITLE =~ /-init$/'
        when: always
      - if: '$CI_COMMIT_BRANCH == "main"'
        when: manual
    needs:
    - init-master
    - init-workers
    - deploy-metallb
    - deploy-openebs

deploy-temporal-workers:
  stage: deploy
  image: alpine/k8s:1.29.13
  variables:
    K8S1: 192.168.69.80
  before_script:
    - apk --no-cache add openssh-client kubectl docker-cli
    # Configure Docker to use insecure registry
    - mkdir -p /etc/docker
    - |
      cat > /etc/docker/daemon.json << EOF
      {
        "insecure-registries": ["git.home:5050"]
      }
      EOF
  script:
    - mkdir ~/.kube
    - scp -i key -o StrictHostKeyChecking=no k8s@"$K8S1":~/.kube/config ~/.kube/config
    - export KUBECONFIG=~/.kube/config

    # Login to GitLab registry using HTTP
    - echo "$GITLABACCESSTOKEN" | docker login -u $GITLABUSERNAME --password-stdin http://git.home:5050 --insecure 

    # Create GitLab registry secret
    - |
      kubectl create secret docker-registry gitlab-registry-secret \
        --docker-server=http://git.home:5050 \
        --docker-username=$GITLABUSERNAME \
        --docker-password=$GITLABACCESSTOKEN \
        --docker-email=$GITLAB_USER_EMAIL \
        --namespace=temporal || true

    # Deploy Python worker
    - sed "s|\${REGISTRY}|$REGISTRY_PATH|g" workers/k8s/python-worker.yaml | kubectl apply -f -

    # Deploy TypeScript worker
    - sed "s|\${REGISTRY}|$REGISTRY_PATH|g" workers/k8s/typescript-worker.yaml | kubectl apply -f -

    # Deploy Go worker
    - sed "s|\${REGISTRY}|$REGISTRY_PATH|g" workers/k8s/go-worker.yaml | kubectl apply -f -

    # Debug pod status
    - echo "Checking pod status..."
    - kubectl get pods -n temporal
    - echo "Checking pod events..."
    - kubectl get events -n temporal --sort-by='.lastTimestamp'

    # Wait for deployments with timeout and debug
    - |
      for deployment in python-worker typescript-worker go-worker; do
        echo "Waiting for $deployment deployment..."
        kubectl rollout status deployment/$deployment -n temporal --timeout=300s || {
          echo "Deployment $deployment failed to roll out. Checking pod status..."
          kubectl get pods -n temporal -l app=$deployment
          kubectl describe pods -n temporal -l app=$deployment
          exit 1
        }
      done
  rules:
    - if: $CI_COMMIT_BRANCH == "main"
      when: always
    - when: manual
  environment:
    name: production
  needs:
    - init-master
    - init-workers
    - deploy-metallb
    - deploy-openebs
    - deploy-temporal


test-temporal-workflow:
  stage: test
  image: python:3.9
  services:
    - name: temporalio/auto-setup:1.22.3
      alias: temporal
      command: ["--db", "postgresql", "--db-port", "5432", "--ui-port", "8080", "--port", "7233", "--metrics-port", "7235", "--log-level", "info", "--namespace", "default"]
    - name: postgres:14
      alias: postgres
      variables:
        POSTGRES_DB: temporal
        POSTGRES_USER: temporal
        POSTGRES_PASSWORD: temporal
  variables:
    TEMPORAL_HOST: 192.168.69.98:7233
    TEMPORAL_NAMESPACE: default
  script:
    - pip install temporalio
    - pip install requests
    - |
      cat > test_workflow.py << 'EOF'
      import asyncio
      from datetime import timedelta
      from temporalio.client import Client
      from temporalio.worker import Worker
      from temporalio import workflow, activity
      from temporalio.common import RetryPolicy

      @workflow.defn
      class TestWorkflow:
          @workflow.run
          async def run(self, name: str) -> str:
              # Start Python activity
              python_result = await workflow.execute_activity(
                  python_activity,
                  "Hello from Python",
                  start_to_close_timeout=timedelta(seconds=5),
                  retry_policy=RetryPolicy(maximum_attempts=3)
              )
              
              # Start TypeScript activity
              typescript_result = await workflow.execute_activity(
                  "ProcessTypeScript",
                  "Hello from TypeScript",
                  start_to_close_timeout=timedelta(seconds=5),
                  retry_policy=RetryPolicy(maximum_attempts=3)
              )
              
              # Start Go activity
              go_result = await workflow.execute_activity(
                  "ProcessGo",
                  "Hello from Go",
                  start_to_close_timeout=timedelta(seconds=5),
                  retry_policy=RetryPolicy(maximum_attempts=3)
              )
              
              return f"Python: {python_result}, TypeScript: {typescript_result}, Go: {go_result}"

      @activity.defn
      async def python_activity(message: str) -> str:
          return f"Python says: {message}"

      async def main():
          # Use the service name instead of localhost
          client = await Client.connect("temporal:7233", namespace="default")
          
          # Start the workflow
          handle = await client.start_workflow(
              TestWorkflow.run,
              "Temporal",
              id="test-workflow",
              task_queue="python-task-queue"
          )
          
          # Wait for the result
          result = await handle.result()
          print(f"Workflow result: {result}")

      if __name__ == "__main__":
          asyncio.run(main())
      EOF
    - python test_workflow.py
  rules:
    - if: $CI_COMMIT_BRANCH == "main"
      when: always
    - when: manual
  environment:
    name: production
  needs:
    - deploy-temporal
    - deploy-temporal-workers


destroy-cluster:
  stage: destroy
  image: 
    name: hashicorp/terraform:latest
    entrypoint: [""]
  before_script:
    - export TF_VAR_username=$(echo "$PVEUSER" | base64 -d)
    - export TF_VAR_password=$(echo "$PVEPASSWORD" | base64 -d)
    - export PROJECT_ID=5
    - export TF_USERNAME=$(echo "$GITLABUSERNAME" | base64 -d)
    - export TF_PASSWORD=$(echo "$GITLABACCESSTOKEN" | base64 -d)
    - export TF_ADDRESS="http://git.home/api/v4/projects/$PROJECT_ID/terraform/state/proxmox-k8s-infra"
    - terraform init -backend-config=address=${TF_ADDRESS} -backend-config=lock_address=${TF_ADDRESS}/lock -backend-config=unlock_address=${TF_ADDRESS}/lock -backend-config=username=${TF_USERNAME} -backend-config=password=${TF_PASSWORD} -backend-config=lock_method=POST -backend-config=unlock_method=DELETE -backend-config=retry_wait_min=5
  script:
    - terraform destroy --auto-approve=true
  allow_failure: true
  rules:
  - when: manual
  needs: []